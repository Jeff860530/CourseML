{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will train REINFORCE with OpenAI Gym's Cartpole environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "gym.logger.set_level(40) # suppress warnings (please remove if gives error)\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0) # set random seed\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the Architecture of the Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box(6,)\n",
      "Atlantis-ram-v0: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('Acrobot-v1')\n",
    "env.seed(0)\n",
    "print('observation space:', env.observation_space)\n",
    "print('Atlantis-ram-v0:', env.action_space)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    #def __init__(self, s_size=4, h_size=16, a_size=2):\n",
    "    def __init__(self, s_size=6, a_size=3):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(s_size, 16)\n",
    "        #self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        #self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        #self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc4 = nn.Linear(16, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = self.fc2(x)\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print():\n",
    "    #env = gym.make('CartPole-v0')\n",
    "    env = gym.make('Acrobot-v1')\n",
    "\n",
    "    state = env.reset()\n",
    "    for t in range(1000):\n",
    "        action, _ = policy.act(state)\n",
    "        env.render()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        #if done:\n",
    "        #    break \n",
    "\n",
    "    env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -336.20\n",
      "Episode 200\tAverage Score: -195.28\n",
      "Episode 300\tAverage Score: -154.33\n",
      "Episode 400\tAverage Score: -131.76\n",
      "Episode 500\tAverage Score: -136.17\n",
      "Episode 600\tAverage Score: -120.69\n",
      "Episode 700\tAverage Score: -129.20\n",
      "Episode 800\tAverage Score: -113.41\n",
      "Episode 900\tAverage Score: -116.49\n",
      "Episode 1000\tAverage Score: -107.82\n"
     ]
    }
   ],
   "source": [
    "policy = Policy().to(device)\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "def reinforce(n_episodes=1000, max_t=1000, gamma=1.0, print_every=100):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        saved_log_probs = []\n",
    "        rewards = []\n",
    "        state = env.reset()\n",
    "        for t in range(max_t):\n",
    "            action, log_prob = policy.act(state)\n",
    "            saved_log_probs.append(log_prob)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break \n",
    "        scores_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "        \n",
    "        discounts = [gamma**i for i in range(len(rewards)+1)]\n",
    "        R = sum([a*b for a,b in zip(discounts, rewards)])\n",
    "        \n",
    "        policy_loss = []\n",
    "        for log_prob in saved_log_probs:\n",
    "            policy_loss.append(-log_prob * R)\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque)>=195.0:\n",
    "            print('Environment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            break\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            torch.save(policy.state_dict(), 'iter%d.pth' % i_episode)\n",
    "            Print()\n",
    "    return scores\n",
    "    \n",
    "scores = reinforce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Display():\n",
    "    env = gym.make('Acrobot-v1')\n",
    "\n",
    "    state = env.reset()\n",
    "    for i in range(10):\n",
    "        iter = (i+1)*100\n",
    "        policy.load_state_dict(torch.load('iter%d.pth'% iter))\n",
    "        for t in range(1000):\n",
    "            action, _ = policy.act(state)\n",
    "            env.render()\n",
    "            state, reward, done, _ = env.step(action)\n",
    "        #if done:\n",
    "        #    break \n",
    "\n",
    "    env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-491cc63225f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-7fe3266d82de>\u001b[0m in \u001b[0;36mDisplay\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#if done:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/gym/envs/classic_control/acrobot.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mcirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# TODO canvas.flip?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vsync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_vsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mglx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglXSwapBuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglx_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36m_wait_vsync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mglxext_arb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglXGetVideoSyncSGI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mglxext_arb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglXWaitVideoSyncSGI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('Acrobot-v1')\n",
    "\n",
    "state = env.reset()\n",
    "for t in range(1000):\n",
    "    action, _ = policy.act(state)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    #if done:\n",
    "    #    break \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
